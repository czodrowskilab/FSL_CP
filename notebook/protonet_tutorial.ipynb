{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: Evaluating a Prototypical Network on FSL-CP "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there is no 'standard' way of doing meta/few-shot learning, models can have vastly different architectures and train very differently. Hence, one might have to change some details in this notebook to work with their own architecture. Nonetheless, this is a good starting point to familiarise yourself with the process of evaluating models on the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting things up for importing local modules\n",
    "import os \n",
    "import sys\n",
    "\n",
    "# Add folder FSL_CP to sys.path\n",
    "FSL_CP_PATH = os.path.join(os.environ['HOME'], 'FSL_CP')\n",
    "sys.path.insert(0, FSL_CP_PATH)\n",
    "\n",
    "# Change working directory to FSL_CP\n",
    "os.chdir(FSL_CP_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from fsl_cp.utils.misc import sliding_average\n",
    "from fsl_cp.utils.metrics import delta_auprc\n",
    "from fsl_cp.datamodule.base import BaseDatasetCP, BaseSamplerCP\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import balanced_accuracy_score, f1_score, cohen_kappa_score, roc_auc_score, accuracy_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate every model over 100 test episodes take average of the scores. In addition, performances are recorded over different support set sizes (8, 16, 32, 64, 96)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisations\n",
    "support_set_sizes = [8, 16, 32, 64, 96]\n",
    "query_set_size = 32\n",
    "num_episodes_val = 100\n",
    "num_episodes_test = 100\n",
    "log_update_freq = 10\n",
    "val_freq = 100\n",
    "\n",
    "# Hyperparameters to tune\n",
    "num_episodes_train = 1000\n",
    "meta_batch_size=3\n",
    "step_size = 500\n",
    "\n",
    "json_path = os.path.join(FSL_CP_PATH, 'data/output/data_split.json')\n",
    "label_df_path= os.path.join(FSL_CP_PATH, 'data/output/FINAL_LABEL_DF.csv')\n",
    "df_assay_id_map_path = os.path.join(FSL_CP_PATH, 'data/output/assay_target_map.csv') \n",
    "cp_f_path=[os.path.join(FSL_CP_PATH,'data/output/norm_CP_feature_df.csv')]\n",
    "\n",
    "# What device to use? Change to 'cpu' if you don't have gpu\n",
    "device = 'cuda:0'\n",
    "\n",
    "# Output paths\n",
    "result_summary_path1 = os.path.join(FSL_CP_PATH, \"notebook/result_summary/protonet_cp_auroc_result_summary.csv\") \n",
    "result_summary_path2 = os.path.join(FSL_CP_PATH, \"notebook/result_summary/protonet_cp_dauprc_result_summary.csv\") \n",
    "result_summary_path3 = os.path.join(FSL_CP_PATH, \"notebook/result_summary/protonet_cp_bacc_result_summary.csv\") \n",
    "result_summary_path4 = os.path.join(FSL_CP_PATH, \"notebook/result_summary/protonet_cp_f1_result_summary.csv\") \n",
    "result_summary_path5 = os.path.join(FSL_CP_PATH, \"notebook/result_summary/protonet_cp_kappa_result_summary.csv\") "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Information about which assays are in the train/validation/test set is stored in a JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the assay keys.\n",
    "with open(json_path) as f:\n",
    "    data = json.load(f)\n",
    "train_split = data['train']\n",
    "val_split = data['val']\n",
    "test_split = data['test']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model performances are stored in Pandas dataframes and saved in csv files. We record performances according to 5 metrics: area under ROC curve, balanced accuray, f1 score, Cohen's Kappa and (delta) area under Precision-Recall curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final result dictionary.\n",
    "\n",
    "final_result_auroc = {\n",
    "    '8': [],\n",
    "    '16': [],\n",
    "    '32': [],\n",
    "    '64': [],\n",
    "    '96': []\n",
    "}\n",
    "final_result_dauprc = {\n",
    "    '8': [],\n",
    "    '16': [],\n",
    "    '32': [],\n",
    "    '64': [],\n",
    "    '96': []\n",
    "}\n",
    "final_result_bacc = {\n",
    "    '8': [],\n",
    "    '16': [],\n",
    "    '32': [],\n",
    "    '64': [],\n",
    "    '96': []\n",
    "}\n",
    "final_result_f1 = {\n",
    "    '8': [],\n",
    "    '16': [],\n",
    "    '32': [],\n",
    "    '64': [],\n",
    "    '96': []\n",
    "}\n",
    "final_result_kappa = {\n",
    "    '8': [],\n",
    "    '16': [],\n",
    "    '32': [],\n",
    "    '64': [],\n",
    "    '96': []\n",
    "}\n",
    "\n",
    "final_result_auroc['ASSAY_ID'] = test_split\n",
    "final_result_dauprc['ASSAY_ID'] = test_split\n",
    "final_result_bacc['ASSAY_ID'] = test_split\n",
    "final_result_f1['ASSAY_ID'] = test_split\n",
    "final_result_kappa['ASSAY_ID'] = test_split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this example, we pick a simple Prototypical Network (Snell et al., 2017) using a 2-hidden-layer fully-connected neural network as backbone.\n",
    "\n",
    "Every compound has an image and a feature representation, but for the sake of simplicity, we will focus on feature representation (or 'CP features' as it is called in the paper)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prototypical Network with a simple backbone \n",
    "\n",
    "class fnn(nn.Module):\n",
    "    \"\"\"Simple fully-connected neural network with 2 hidden layers.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_classes=512, input_shape=None):\n",
    "        super(fnn, self).__init__()\n",
    "        assert input_shape\n",
    "        fc_units = 2048\n",
    "        drop_prob = 0.5\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.Linear(input_shape, fc_units),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=drop_prob),\n",
    "            nn.Linear(fc_units, fc_units),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=drop_prob),\n",
    "            nn.Linear(fc_units, num_classes),\n",
    "        )\n",
    "        \n",
    "        # init\n",
    "        self.init_parameters()\n",
    "    \n",
    "    def init_parameters(self):\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Linear):\n",
    "                nn.init.xavier_normal_(module.weight)\n",
    "                nn.init.constant_(module.bias, 0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.classifier(x)\n",
    "    \n",
    "\n",
    "class ProtoNet(nn.Module):\n",
    "    \"\"\" Prototypical Network with Euclidean distance.\n",
    "    \"\"\"\n",
    "    def __init__(self, backbone: nn.Module):\n",
    "        super(ProtoNet, self).__init__()\n",
    "        self.backbone = backbone\n",
    "    \n",
    "    def forward(\n",
    "        self,\n",
    "        support_images: torch.Tensor,\n",
    "        support_labels: torch.Tensor,\n",
    "        query_images: torch.Tensor\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Predict query labels using support images with labels.\n",
    "        \"\"\"\n",
    "        z_support = self.backbone.forward(support_images)\n",
    "        z_query = self.backbone.forward(query_images)\n",
    "        #n_way = 2\n",
    "        n_way = len(torch.unique(support_labels))\n",
    "        z_proto = torch.cat(\n",
    "            [\n",
    "                z_support[torch.nonzero(support_labels==label)].mean(0)\n",
    "                for label in range(n_way)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        dists = torch.cdist(z_query, z_proto)\n",
    "        scores = -dists\n",
    "\n",
    "        return scores"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are some helper functions for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "def fit(\n",
    "        support_images: torch.Tensor,\n",
    "        support_labels: torch.Tensor,\n",
    "        query_images: torch.Tensor,\n",
    "        query_labels: torch.Tensor,\n",
    "        criterion, \n",
    "        optimizer,\n",
    "        model,\n",
    "        device\n",
    "    ) -> float:\n",
    "    \"\"\"(Meta-)Train a protonet model on support and query images and labels. \n",
    "    Return: Loss with the gradient calculated.\n",
    "    \"\"\"\n",
    "    optimizer.zero_grad()\n",
    "    classification_scores = model(\n",
    "        support_images.to(device), support_labels.to(device), query_images.to(device)\n",
    "    )\n",
    "    s = nn.LogSoftmax(dim=1)\n",
    "    log_p = s(classification_scores)\n",
    "    loss = criterion(log_p, query_labels.to(device))\n",
    "    loss.backward()\n",
    "    #optimizer.step()\n",
    "\n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "def evaluate_on_one_task(\n",
    "    model,\n",
    "    support_images: torch.Tensor,\n",
    "    support_labels: torch.Tensor,\n",
    "    query_images: torch.Tensor,\n",
    "    query_labels: torch.Tensor,\n",
    "    device\n",
    "):\n",
    "    \"\"\"Returns the prediction of the protonet model and the real label.\"\"\"\n",
    "    s = nn.Softmax(dim=1)\n",
    "    pred_float = s(model(support_images.to(device), support_labels.to(device), query_images.to(device))).detach().cpu().numpy()\n",
    "    pred_float = [i[1] for i in pred_float]\n",
    "    pred_round = (\n",
    "    torch.max(\n",
    "        model(support_images.to(device), support_labels.to(device), query_images.to(device))\n",
    "        .detach()\n",
    "        .data,\n",
    "        1,\n",
    "    )[1]).cpu().numpy()\n",
    "    return pred_float, pred_round, query_labels.cpu().numpy()\n",
    "\n",
    "\n",
    "def evaluate(model, data_loader: DataLoader, device):\n",
    "    \"\"\" Evaluate the model on a DataLoader object.\n",
    "    Return means and standard deviations of 5 metrics below.\"\"\"\n",
    "    AUROC_scores = []\n",
    "    dAUPRC_scores = []\n",
    "    bacc_scores = []\n",
    "    F1_scores = []\n",
    "    kappa_scores = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for episode_index, (\n",
    "            support_images,\n",
    "            support_labels,\n",
    "            query_images,\n",
    "            query_labels,\n",
    "            class_ids,\n",
    "        ) in enumerate(data_loader):\n",
    "\n",
    "            y_float, y_pred, y_true = evaluate_on_one_task(\n",
    "                model, support_images, support_labels, query_images, query_labels, device\n",
    "            )\n",
    "            AUROC_score = roc_auc_score(y_true, y_float)\n",
    "            dAUPRC_score = delta_auprc(y_true, y_float)\n",
    "            bacc_score = balanced_accuracy_score(y_true, y_pred, adjusted=True)\n",
    "            F1_score = f1_score(y_true, y_pred)\n",
    "            kappa_score = cohen_kappa_score(y_true, y_pred)\n",
    "\n",
    "            AUROC_scores.append(AUROC_score)\n",
    "            dAUPRC_scores.append(dAUPRC_score)\n",
    "            bacc_scores.append(bacc_score)\n",
    "            F1_scores.append(F1_score)\n",
    "            kappa_scores.append(kappa_score)\n",
    "\n",
    "    return np.mean(AUROC_scores), np.std(AUROC_scores), np.mean(dAUPRC_scores), np.std(dAUPRC_scores), np.mean(bacc_scores), \\\n",
    "        np.std(bacc_scores), np.mean(F1_scores), np.std(F1_scores), np.mean(kappa_scores), np.std(kappa_scores)\n",
    "\n",
    "\n",
    "def eval(model, data_loader: DataLoader, device):\n",
    "    \"\"\" Evaluate the model on a DataLoader object.\n",
    "    Only returns accuracy.\"\"\"\n",
    "    acc_scores = []\n",
    "    with torch.no_grad():\n",
    "        for episode_index, (\n",
    "            support_images,\n",
    "            support_labels,\n",
    "            query_images,\n",
    "            query_labels,\n",
    "            class_ids,\n",
    "        ) in enumerate(data_loader):\n",
    "\n",
    "            y_float, y_pred, y_true = evaluate_on_one_task(\n",
    "                model, support_images, support_labels, query_images, query_labels, device\n",
    "            )\n",
    "            acc_scores.append(accuracy_score(y_true, y_pred))\n",
    "    return np.mean(acc_scores)\n",
    "           "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the main traning loop. It loops through all support set sizes, train the model then to few-shot prediction on the test assays. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysing for support set size 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [02:30<00:00, 19.98it/s, lr=[1e-05], train_loss=1.24, val_acc=0.763]  \n",
      "100%|██████████| 18/18 [02:46<00:00,  9.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysing for support set size 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [02:29<00:00, 20.04it/s, lr=[1e-05], train_loss=0.478, val_acc=0.79]  \n",
      "100%|██████████| 18/18 [02:38<00:00,  8.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysing for support set size 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [02:34<00:00, 19.40it/s, lr=[1e-05], train_loss=0.51, val_acc=0.786]  \n",
      "100%|██████████| 18/18 [02:43<00:00,  9.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysing for support set size 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [02:34<00:00, 19.45it/s, lr=[1e-05], train_loss=0.421, val_acc=0.789] \n",
      "100%|██████████| 18/18 [02:47<00:00,  9.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysing for support set size 96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [02:34<00:00, 19.44it/s, lr=[1e-05], train_loss=0.391, val_acc=0.761] \n",
      "100%|██████████| 18/18 [02:50<00:00,  9.47s/it]\n"
     ]
    }
   ],
   "source": [
    "# Loop through all support set size, performing few-shot prediction.\n",
    "for support_set_size in support_set_sizes:\n",
    "    tqdm.write(f\"Analysing for support set size {support_set_size}\")\n",
    "\n",
    "    # Load train data.\n",
    "    train_data = BaseDatasetCP(\n",
    "        train_split, \n",
    "        label_df_path= label_df_path, \n",
    "        cp_f_path=cp_f_path\n",
    "    )\n",
    "    train_sampler = BaseSamplerCP(\n",
    "            task_dataset=train_data,\n",
    "            support_set_size=support_set_size,\n",
    "            query_set_size=query_set_size,\n",
    "            num_episodes=num_episodes_train,\n",
    "            meta_batch_size=meta_batch_size\n",
    "    )\n",
    "    train_loader = DataLoader(\n",
    "            train_data,\n",
    "            batch_sampler=train_sampler,\n",
    "            num_workers=12,\n",
    "            pin_memory=True,\n",
    "            collate_fn=train_sampler.episodic_collate_fn,\n",
    "    )\n",
    "\n",
    "    # Load val data.\n",
    "    val_data = BaseDatasetCP(\n",
    "        val_split, \n",
    "        label_df_path= label_df_path, \n",
    "        cp_f_path=cp_f_path\n",
    "    )\n",
    "    val_sampler = BaseSamplerCP(\n",
    "            task_dataset=val_data,\n",
    "            support_set_size=support_set_size,\n",
    "            query_set_size=query_set_size,\n",
    "            num_episodes=num_episodes_val,\n",
    "            meta_batch_size=meta_batch_size\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "            val_data,\n",
    "            batch_sampler=val_sampler,\n",
    "            num_workers=12,\n",
    "            pin_memory=True,\n",
    "            collate_fn=val_sampler.episodic_collate_fn,\n",
    "    )\n",
    "\n",
    "    # Load model.\n",
    "    input_shape=len(train_data[3][0])\n",
    "    backbone = fnn(num_classes=512, input_shape=input_shape) \n",
    "    model = ProtoNet(backbone).to(device)\n",
    "\n",
    "    # Meta-pretraining the protonet.\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    opt = optim.Adam(model.parameters(), lr=0.0001)\n",
    "    scheduler = StepLR(opt, step_size=step_size, gamma=0.1)\n",
    "    all_loss = []\n",
    "    model.train()\n",
    "    with tqdm(enumerate(train_loader), total=len(train_loader), leave=True) as tqdm_train:\n",
    "        for episode_index, (\n",
    "            support_images,\n",
    "            support_labels,\n",
    "            query_images,\n",
    "            query_labels,\n",
    "            _,\n",
    "        ) in tqdm_train:\n",
    "            \n",
    "            # Fit model to data\n",
    "            loss_value = fit(support_images, support_labels, query_images, query_labels, criterion, opt, model, device) \n",
    "\n",
    "            # Optimizer steps after accumulating gradients from 'meta_batch_size' batches \n",
    "            if (episode_index+1) % meta_batch_size == 0:\n",
    "                opt.step() \n",
    "                scheduler.step() # Learning rate decay after a fixed time \n",
    "\n",
    "            # Update the loss on the progress bar\n",
    "            all_loss.append(loss_value)\n",
    "            if episode_index % log_update_freq == 0:\n",
    "                if episode_index % val_freq == 0:\n",
    "                    val_acc = eval(model, val_loader, device)\n",
    "\n",
    "                tqdm_train.set_postfix(val_acc=val_acc, train_loss=sliding_average(all_loss, log_update_freq), lr=scheduler.get_last_lr())\n",
    "            \n",
    "\n",
    "    # Perform inference on all test assays.\n",
    "    for test_assay in tqdm(test_split):\n",
    "        \n",
    "        # Load test data.\n",
    "        test_data = BaseDatasetCP(\n",
    "            test_split, \n",
    "            label_df_path= label_df_path, \n",
    "            cp_f_path=cp_f_path\n",
    "        )\n",
    "        test_sampler = BaseSamplerCP(\n",
    "            task_dataset=test_data,\n",
    "            support_set_size=support_set_size,\n",
    "            query_set_size=query_set_size,\n",
    "            num_episodes=num_episodes_test,\n",
    "            meta_batch_size=meta_batch_size\n",
    "        )\n",
    "        test_loader = DataLoader(\n",
    "            test_data,\n",
    "            batch_sampler=test_sampler,\n",
    "            num_workers=12,\n",
    "            pin_memory=True,\n",
    "            collate_fn=test_sampler.episodic_collate_fn,\n",
    "        )\n",
    "\n",
    "        # Evaluate the performance of the model.\n",
    "        auroc_mean, auroc_std, dauprc_mean, dauprc_std, bacc_mean, bacc_std, f1_mean, f1_std, kappa_mean, kappa_std = evaluate(\n",
    "            model, \n",
    "            test_loader, \n",
    "            device\n",
    "        )\n",
    "        final_result_auroc[str(support_set_size)].append(f\"{auroc_mean:.2f}+/-{auroc_std:.2f}\")\n",
    "        final_result_dauprc[str(support_set_size)].append(f\"{dauprc_mean:.2f}+/-{dauprc_std:.2f}\")\n",
    "        final_result_bacc[str(support_set_size)].append(f\"{bacc_mean:.2f}+/-{bacc_std:.2f}\")\n",
    "        final_result_f1[str(support_set_size)].append(f\"{f1_mean:.2f}+/-{f1_std:.2f}\")\n",
    "        final_result_kappa[str(support_set_size)].append(f\"{kappa_mean:.2f}+/-{kappa_std:.2f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above loop takes around 30 mins to train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, save the dataframes to csv files in the correct format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and save result summary csv files.\n",
    "df_assay_id_map = pd.read_csv(df_assay_id_map_path)\n",
    "df_assay_id_map = df_assay_id_map.astype({'ASSAY_ID': str})\n",
    "\n",
    "df_score = pd.DataFrame(data=final_result_auroc)\n",
    "df_final = pd.merge(df_assay_id_map[['ASSAY_ID', 'assay_chembl_id']], df_score, on='ASSAY_ID', how='right')\n",
    "df_final.to_csv(result_summary_path1, index=False)\n",
    "\n",
    "df_score = pd.DataFrame(data=final_result_dauprc)\n",
    "df_final = pd.merge(df_assay_id_map[['ASSAY_ID', 'assay_chembl_id']], df_score, on='ASSAY_ID', how='right')\n",
    "df_final.to_csv(result_summary_path2, index=False)\n",
    "\n",
    "df_score = pd.DataFrame(data=final_result_bacc)\n",
    "df_final = pd.merge(df_assay_id_map[['ASSAY_ID', 'assay_chembl_id']], df_score, on='ASSAY_ID', how='right')\n",
    "df_final.to_csv(result_summary_path3, index=False)\n",
    "\n",
    "df_score = pd.DataFrame(data=final_result_f1)\n",
    "df_final = pd.merge(df_assay_id_map[['ASSAY_ID', 'assay_chembl_id']], df_score, on='ASSAY_ID', how='right')\n",
    "df_final.to_csv(result_summary_path4, index=False)\n",
    "\n",
    "df_score = pd.DataFrame(data=final_result_kappa)\n",
    "df_final = pd.merge(df_assay_id_map[['ASSAY_ID', 'assay_chembl_id']], df_score, on='ASSAY_ID', how='right')\n",
    "df_final.to_csv(result_summary_path5, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fsl-cp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
